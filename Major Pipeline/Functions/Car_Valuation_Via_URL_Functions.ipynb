{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001232ed",
   "metadata": {},
   "source": [
    "# Get the Car Observation from the requested URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c515ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_car_offer_val(url):\n",
    "    # scrape_car_offer_val function begins\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        html = response.text\n",
    "        doc = BeautifulSoup(html, \"html.parser\")\n",
    "        \n",
    "    # Process done by the function\n",
    "        curr_car_dict = {}\n",
    "        attribute_exception_list = ['Some', 'Attributes', 'To', 'Exclude']  # Update this list with actual attributes to exclude\n",
    "\n",
    "        for key, value in zip(doc.find_all(\"dt\"), doc.find_all(\"dd\")):\n",
    "            if key.text not in attribute_exception_list:\n",
    "                curr_car_dict[key.text.replace(\"\\n\", \"\")] = value.text.replace(\"\\n\", \"\")\n",
    "\n",
    "        curr_car_dict[\"url\"] = url\n",
    "        curr_car_dict[\"date\"] = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        curr_car_dict[\"time\"] = datetime.now().strftime(\"%H-%M-%S\")\n",
    "        curr_car_dict[\"model\"] = doc.find(\"span\", class_=\"StageTitle_model__EbfjC StageTitle_boldClassifiedInfo__sQb0l\").get_text()\n",
    "        curr_car_dict[\"brand\"] = doc.find(\"span\", class_=\"StageTitle_boldClassifiedInfo__sQb0l\").get_text()\n",
    "\n",
    "        # Check if the price column exists, if not, add it\n",
    "        if 'Barzahlungspreis' not in curr_car_dict:\n",
    "            curr_car_dict['Barzahlungspreis'] = re.split(r'(?<=-)', doc.find('div', class_='PriceInfo_wrapper__hreB_').find('span', class_='PriceInfo_price__XU0aF').text.strip())[0]\n",
    "\n",
    "        # Create DataFrame from the dictionary\n",
    "        car_offer_df = pd.DataFrame.from_dict(curr_car_dict, orient=\"index\").T\n",
    "\n",
    "        return car_offer_df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while scraping the URL: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6e6c03",
   "metadata": {},
   "source": [
    "# Clean and Dummy New Observation in One"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4e3934",
   "metadata": {},
   "source": [
    "## Match Format of New Observation with Cleaned/Dummy Transformed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e63dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_with_first_columns_val(df_list):\n",
    "    # concat_with_first_columns_val function begins\n",
    "\n",
    "    # Process done by the function\n",
    "    if not df_list:\n",
    "        return pd.DataFrame()  # Return an empty DataFrame if the list is empty\n",
    "    \n",
    "    first_df = df_list[0]\n",
    "    other_dfs = df_list[1:]\n",
    "    \n",
    "    # Reindex other DataFrames to match the columns of the first DataFrame\n",
    "    reindexed_dfs = [first_df] + [df.reindex(columns=first_df.columns) for df in other_dfs]\n",
    "    \n",
    "    return pd.concat(reindexed_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2781e",
   "metadata": {},
   "source": [
    "## Preprocess Observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "551777db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_car_data_val(url, scraped_data_path, helper_data_path_cleaned, helper_data_path_dummied, output_path):\n",
    "    # process_car_data_val function begins\n",
    "    # Set the maximum number of displayed rows and columns\n",
    "    pd.set_option('display.max_rows', 1000)\n",
    "    pd.set_option('display.max_columns', 1000)\n",
    "\n",
    "    # Process done by the function\n",
    "    # Import scraped data\n",
    "    scraped_data = pd.read_csv(scraped_data_path, low_memory=False)\n",
    "\n",
    "    # Get new car observation from URL\n",
    "\n",
    "    new_car_observation = scrape_car_offer_val(url)\n",
    "\n",
    "    # Reduce scraped data\n",
    "    brand_list = new_car_observation[\"brand\"].tolist()\n",
    "    model_list = new_car_observation[\"model\"].tolist()\n",
    "    \n",
    "    reduced_scraped_data = pd.DataFrame()\n",
    "    \n",
    "    for curr_brand, curr_model in zip(brand_list, model_list):\n",
    "        curr_df = scraped_data[(scraped_data[\"brand\"] == curr_brand) & (scraped_data[\"model\"] == curr_model)]\n",
    "        reduced_scraped_data = pd.concat([reduced_scraped_data, curr_df])\n",
    "\n",
    "    # Delete full scraped data to save memory\n",
    "    if \"scraped_data\" in globals():\n",
    "        \n",
    "        del scraped_data\n",
    "        gc.collect()\n",
    "\n",
    "    # Append new observation to scraped data\n",
    "    processing_data = pd.concat([reduced_scraped_data, new_car_observation])\n",
    "\n",
    "    # Clean dataframe from observation where values have shifted\n",
    "    allowance_dict = {\"Umweltplakette\": [\"1 (Keine)\", \"4 (Grün)\", \"3 (Gelb)\", \"2 (Rot)\", np.nan],\n",
    "                      \"Antriebsart\": ['Heck', 'Front', 'Allrad', np.nan],\n",
    "                      \"Scheckheftgepflegt\": [\"Ja\", \"Nein\", np.nan]}\n",
    "    df_step2 = clean_from_rows_with_shifted_columns(processing_data)\n",
    "\n",
    "    # Drop unnamed columns\n",
    "    df_step3_1 = drop_unnamed_columns(df_step2)\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    columns_to_drop = [\"€ 0,-\", \"Pkw Zulassung\", \"Ladevolumen\", \"zul. Zuggewicht\", \"Achsen\", \"Nutzlast\", \"Radstand\", \"Laderaumhöhe\",\n",
    "                       \"Laderaumbreite\", \"Laderaumlänge\", \"zul. Gesamtgewicht\", \"Sonderzahlung\", \"Verfügbarkeit\", \"Batteriebesitz\",\n",
    "                       \"Letzter Zahnriemenwechsel\", \"Verfügbar ab\", \"Fahrzeugstand\", \"Energieeffizienzklasse\", \"CO₂-Effizienz\",\n",
    "                       \"Bearbeitungsgebühren\", \"Bruttodarlehensbetrag\", \"Sollzins geb. p.a.\", \"Letzte Inspektion\", \"Baujahr\",\n",
    "                       \"CO₂-Klasse\", \"Schlüsselnummer\", \"Gänge\", \"Angebotsnummer\", \"Farbe laut Hersteller\",\n",
    "                       \"Farbe der Innenausstattung\", \"Andere Energieträger\", \"Fahrzeugzustand\",\n",
    "                       \"Ladezeit von 10% bis 80%\", \"Fahrleistung p.a.\", \"Zulassungskosten\", \"HU\"]\n",
    "    df_step3_2 = drop_unwanted_columns(df_step3_1, columns_to_drop)\n",
    "\n",
    "    df_step3_2[\"Elektrische Reichweite7\"] = 0\n",
    "    df_step3_2[\"Fahrzeughalter\"] = df_step3_2[\"Fahrzeughalter\"].apply(lambda x: 1 if isinstance(x, str) else x)\n",
    "    df_step3_2[\"Fahrzeughalter\"] = df_step3_2[\"Fahrzeughalter\"].fillna(1)\n",
    "    \n",
    "    # Keep wanted columns\n",
    "    wanted_columns = [\n",
    "        'Barzahlungspreis', 'brand', 'model', 'Kilometerstand', 'Leistung', 'Kraftstoff', 'Antriebsart', 'Karosserieform',\n",
    "        'Fahrzeugart', 'Sitzplätze', 'Türen', 'Fahrzeughalter', 'Getriebe', 'Hubraum', 'Zylinder', 'Kraftstoffverbrauch',\n",
    "        'Schadstoffklasse', 'Umweltplakette', 'Komfort', 'Extras', 'Außenfarbe', 'Innenausstattung', 'url',\n",
    "        'Nichtraucherfahrzeug', 'Leergewicht', 'Unterhaltung/Media', 'Sicherheit', 'CO₂-Emissionen', 'Lackierung',\n",
    "        'Scheckheftgepflegt', 'Garantie', 'Taxi oder Mietwagen', 'Stromverbrauch', 'Elektrische Reichweite', \n",
    "        \"Elektrische Reichweite7\", 'date', 'Erstzulassung', 'time']\n",
    "    df_step3_2 = df_step3_2[wanted_columns]\n",
    "\n",
    "    # Merge columns\n",
    "    df_step3_3_1 = merge_columns(df_step3_2, \"Elektrische Reichweite\", \"Elektrische Reichweite7\")\n",
    "\n",
    "    # Convert strings to floats/integers\n",
    "    replacement_dict_garantie = {\"Nein\": \"0\", \"Ja\": \"12\"}\n",
    "    df_step4_1_1 = replace_values_single(df_step3_3_1, \"Garantie\", replacement_dict_garantie)\n",
    "\n",
    "    replacement_dict_brand = {\"porsche\": \"Porsche\", \"audi\": \"Audi\", \"opel\": \"Opel\", \"skoda\": \"Skoda\", \"toyota\": \"Toyota\"}\n",
    "    df_step4_1_1 = replace_values_single(df_step4_1_1, \"brand\", replacement_dict_brand)\n",
    "\n",
    "    replacement_dict = {\"Stromverbrauch\": {\",\": \".\"}, \"Leistung\": {\",\": \".\"}, \"Hubraum\": {\",\": \".\"},\n",
    "                        \"Leergewicht\": {\",\": \".\"}, \"CO₂-Emissionen\": {\",\": \".\"}, \"Kilometerstand\": {\".\": \"\"}}\n",
    "    df_step4_1_2 = replace_values_multiple(df_step4_1_1, replacement_dict)\n",
    "\n",
    "    column_names = [\"brand\", \"model\"]\n",
    "    df_step4_1_3 = remove_trailing_whitespace(df_step4_1_2, column_names)\n",
    "\n",
    "    df_step4_1_4 = transform_fuel_types(df_step4_1_3, \"Kraftstoff\")\n",
    "\n",
    "    split_dict_simple = {\"Garantie\": \" \", \"Stromverbrauch\": \" \", \"Leistung\": \" \", \"Hubraum\": \" \", \"Leergewicht\": \" \"}\n",
    "    df_step4_2_1 = split_string_to_1integer(df_step4_1_4, split_dict_simple)\n",
    "\n",
    "    df_step4_2_1[\"CO₂-Emissionen\"] = df_step4_2_1[\"CO₂-Emissionen\"].astype(str)\n",
    "    df_step4_2_1[\"CO₂-Emissionen\"] = df_step4_2_1[\"CO₂-Emissionen\"].fillna(\"20\")\n",
    "    \n",
    "    df_step4_2_1[\"Kilometerstand\"] = df_step4_2_1[\"Kilometerstand\"].astype(str)\n",
    "    df_step4_2_1[\"Kilometerstand\"] = df_step4_2_1[\"Kilometerstand\"].fillna(\"2000km\")\n",
    "    \n",
    "    df_step4_2_1[\"Elektrische Reichweite\"] = df_step4_2_1[\"Elektrische Reichweite\"].astype(str)\n",
    "    df_step4_2_1[\"Elektrische Reichweite\"] = df_step4_2_1[\"Elektrische Reichweite\"].fillna(\"0km\")\n",
    "    \n",
    "    split_dict_complex = {\"CO₂-Emissionen\": \" \", \"Kilometerstand\": \" \", \"Elektrische Reichweite\": \" \"}\n",
    "    df_step4_2_2 = split_string_to_1integer_complex(df_step4_2_1, split_dict_complex)\n",
    "\n",
    "    df_step4_3_1 = convert_fuel_consumption(df_step4_2_2, \"Kraftstoffverbrauch\")\n",
    "    df_step4_3_2 = convert_barzahlungspreis_to_float(df_step4_3_1, \"Barzahlungspreis\")\n",
    "\n",
    "    replacement_dict_default = {\"Scheckheftgepflegt\": [\"Nein\"], \"Nichtraucherfahrzeug\": [\"Nein\"], \"Garantie\": [0],\n",
    "                                \"Taxi oder Mietwagen\": [\"Nein\"], \"Stromverbrauch\": [0], \"Elektrische Reichweite\": [0],\n",
    "                                \"Lackierung\": [\"Keine Angabe\"], \"Außenfarbe\": [\"keine\"]}\n",
    "    df_step5_1 = missing_values_to_default(df_step4_3_2, replacement_dict_default)\n",
    "\n",
    "    df_step5_2_1 = get_median_value_based_on_erstzulassung(df_step5_1, \"Fahrzeughalter\", \"Erstzulassung\")\n",
    "\n",
    "    replacement_columns_2groups = [\"Antriebsart\", \"Sitzplätze\", \"Türen\"]\n",
    "    df_step5_2_2 = fill_missing_with_mode_by_2groups(df_step5_2_1, replacement_columns_2groups, \"brand\", \"model\")\n",
    "\n",
    "    replacement_columns_3groups = [\"Schadstoffklasse\", \"Umweltplakette\", \"Getriebe\", \"Hubraum\",\n",
    "                                   \"CO₂-Emissionen\", \"Zylinder\", \"Leergewicht\", \"Kraftstoff\"]\n",
    "    df_step5_2_3 = fill_missing_with_mode_by_3groups(df_step5_2_2, replacement_columns_3groups, \"brand\", \"model\", \"Leistung\")\n",
    "\n",
    "    # Split multi-feature columns\n",
    "    features_to_columns = [\"Sicherheit\", \"Innenausstattung\", \"Unterhaltung/Media\", \"Extras\", \"Komfort\"]\n",
    "    df_step6 = create_feature_columns(df_step5_2_3, features_to_columns)\n",
    "\n",
    "    columns_to_drop_features = [\"Sicherheit\", \"Innenausstattung\", \"Unterhaltung/Media\", \"Extras\", \"Komfort\"]\n",
    "    df_step6 = drop_unwanted_columns(df_step6, columns_to_drop_features)\n",
    "\n",
    "    # Date columns\n",
    "    df_step7_1_1 = convert_to_timestamp(df_step6, \"date\", \"time\")\n",
    "    df_step7_1_2 = drop_unwanted_columns(df_step7_1_1, [\"time\", \"date\"])\n",
    "    df_step7_2_1 = split_month_year(df_step7_1_2, \"Erstzulassung\")\n",
    "    df_step7_2_2 = convert_zulassung_to_age(df_step7_2_1, \"Erstzulassung_Jahr\", \"Erstzulassung_Monat\")\n",
    "    df_step7_2_3 = drop_unwanted_columns(df_step7_2_2, [\"Erstzulassung\", \"Erstzulassung_Monat\"])\n",
    "\n",
    "    # Rename columns\n",
    "    rename_dict = {\"Barzahlungspreis\": \"Preis\", \"Leistung\": \"Leistung_PS\", \"CO₂-Emissionen\": \"CO2-Emissionen\",\n",
    "                   \"model\": \"Modell\", \"brand\": \"Hersteller\", \"url\": \"URL\"}\n",
    "    df_step10_1 = df_step7_2_3.rename(columns=rename_dict)\n",
    "\n",
    "    translation_dict = {\n",
    "        'Preis': 'Price', 'Hersteller': 'Manufacturer', 'Modell': 'Model', 'Kilometerstand': 'Mileage',\n",
    "        'Leistung_PS': 'Power_HP', 'Kraftstoff': 'Fuel', 'Antriebsart': 'Drive_type', 'Karosserieform': 'Body_type',\n",
    "        'Fahrzeugart': 'Vehicle_type', 'Sitzplätze': 'Seats', 'Türen': 'Doors', 'Fahrzeughalter': 'Owners',\n",
    "        'Getriebe': 'Transmission', 'Hubraum': 'Displacement', 'Zylinder': 'Cylinders', 'Kraftstoffverbrauch': 'Fuel_consumption',\n",
    "        'Schadstoffklasse': 'Emission_class', 'Umweltplakette': 'Environmental_sticker', 'Komfort': 'Comfort', 'Extras': 'Extras',\n",
    "        'Außenfarbe': 'Exterior_color', 'Innenausstattung': 'Interior_features', 'URL': 'URL',\n",
    "        'Nichtraucherfahrzeug': 'Non_smoker_vehicle', 'Leergewicht': 'Curb_weight', 'Unterhaltung/Media': 'Entertainment/Media',\n",
    "        'Sicherheit': 'Safety', 'CO2-Emissionen': 'CO2_emissions', 'Lackierung': 'Paint', 'Scheckheftgepflegt': 'Full_service_history',\n",
    "        'Garantie': 'Warranty', 'Taxi oder Mietwagen': 'Taxi_or_rental', 'Stromverbrauch': 'Electricity_consumption',\n",
    "        'Elektrische Reichweite': 'Electric_range', 'date_scraped': 'Date_scraped', 'Alter': 'Age'}\n",
    "    df_step10_2 = df_step10_1.rename(columns=translation_dict)\n",
    "\n",
    "    # Rearrange columns\n",
    "    first_columns = [\"Price\", \"Manufacturer\", \"Model\", \"Mileage\", \"Power_HP\", \"Fuel\", \"Drive_type\"]\n",
    "    df_step11 = rearrange_columns(df_step10_2, first_columns)\n",
    "\n",
    "    # Reduce data back to wanted observation\n",
    "    cleaned_new_observation = df_step11[df_step11[\"URL\"] == url]\n",
    "\n",
    "    # Fill rest of NaNs\n",
    "    cleaned_new_observation = cleaned_new_observation.fillna(0)\n",
    "\n",
    "    # Use helper data to get the right shape\n",
    "    most_recent_file = get_most_recent_file(helper_data_path_cleaned, 1)\n",
    "    helper_data_cleaned = pd.read_csv(most_recent_file, low_memory=False)\n",
    "    concatenated_df_cleaned = concat_with_first_columns_val([helper_data_cleaned, cleaned_new_observation])\n",
    "    concatenated_df_cleaned = concatenated_df_cleaned[concatenated_df_cleaned[\"URL\"] == url]\n",
    "\n",
    "    # Dummied helper data\n",
    "    columns_to_integers = [\"Seats\", \"Power_HP\", \"Displacement\", \"Cylinders\", \"Warranty\"]\n",
    "    columns_to_date = [\"Date_scraped\"]\n",
    "    columns_to_floats = []\n",
    "    columns_to_categorical = []\n",
    "    columns_to_drop = []\n",
    "\n",
    "    data_type_transformed = data_type_transformer(concatenated_df_cleaned, columns_to_integers, columns_to_date,\n",
    "                                                  columns_to_floats, columns_to_categorical, columns_to_drop)\n",
    "\n",
    "    columns_to_dummy = list(data_type_transformed.select_dtypes(include=['object']).columns)\n",
    "    columns_to_exclude = [\"URL\", \"Date_scraped\"]\n",
    "\n",
    "    for curr_column in columns_to_exclude:\n",
    "        if curr_column in columns_to_dummy:\n",
    "            columns_to_dummy.remove(curr_column)\n",
    "\n",
    "    data_dummy_transformed = pd.get_dummies(data_type_transformed, columns=columns_to_dummy,\n",
    "                                            drop_first=False, dtype=float)\n",
    "\n",
    "    most_recent_file_dummied = get_most_recent_file(helper_data_path_dummied, 1)\n",
    "    helper_data_dummied = pd.read_csv(most_recent_file_dummied, low_memory=False)\n",
    "    concatenated_df_dummied = concat_with_first_columns_val([helper_data_dummied, data_dummy_transformed])\n",
    "    concatenated_df_dummied = concatenated_df_dummied[concatenated_df_dummied[\"URL\"] == url]\n",
    "\n",
    "    dummied_new_observation = concatenated_df_dummied.fillna(0)\n",
    "    \n",
    "    dummied_new_observation.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    return dummied_new_observation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23332b4b",
   "metadata": {},
   "source": [
    "# Get Prediction Results on New Observation (All in One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66174ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_results_val(url, scraped_data_path, helper_data_path_cleaned, helper_data_path_dummied, output_path,\n",
    "    # get_prediction_results_val function begins\n",
    "                          fixed_procentual_error, target_folder_model):\n",
    "    \n",
    "    # Process done by the function\n",
    "    # get the dummied new observation from URL using the prior defined function\n",
    "    dummied_new_observation = process_car_data_val(url, scraped_data_path, helper_data_path_cleaned, helper_data_path_dummied, output_path)\n",
    "    \n",
    "    \n",
    "    # define if you want the most recent file (1), second most recent (2), ...\n",
    "    n_most_recent_file = 1 \n",
    "\n",
    "    # get the input path\n",
    "    input_path_model = get_data_path(target_folder_model)\n",
    "\n",
    "    # load the model\n",
    "    most_recent_model_file = get_most_recent_file(input_path_model, n_most_recent_file)\n",
    "    xgb_model = joblib.load(most_recent_model_file)\n",
    "    \n",
    "    real_price = dummied_new_observation[\"Price\"]\n",
    "    fair_price = xgb_model.predict(dummied_new_observation.drop(columns=[\"Price\", \"URL\", \"Date_scraped\"]))[0]\n",
    "    \n",
    "    lower_bound = fair_price*(1-fixed_procentual_error)\n",
    "    upper_bound = fair_price*(1+fixed_procentual_error)\n",
    "    \n",
    "    \n",
    "    print(\"Car Valuation Done!\")\n",
    "    \n",
    "    return float(real_price), fair_price, lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_results_preloaded_model_val(url, scraped_data_path, helper_data_path_cleaned, helper_data_path_dummied, output_path,\n",
    "    # get_prediction_results_preloaded_model_val function begins\n",
    "                          fixed_procentual_error, model):\n",
    "    \n",
    "    # Process done by the function\n",
    "    # get the dummied new observation from URL using the prior defined function\n",
    "    dummied_new_observation = process_car_data_val(url, scraped_data_path, helper_data_path_cleaned, helper_data_path_dummied, output_path)\n",
    "    xgb_model = model\n",
    "    \n",
    "    real_price = dummied_new_observation[\"Price\"]\n",
    "    fair_price = xgb_model.predict(dummied_new_observation.drop(columns=[\"Price\", \"URL\", \"Date_scraped\"]))[0]\n",
    "    \n",
    "    lower_bound = fair_price*(1-fixed_procentual_error)\n",
    "    upper_bound = fair_price*(1+fixed_procentual_error)\n",
    "    \n",
    "    \n",
    "    print(\"Car Valuation Done!\")\n",
    "    \n",
    "    return float(real_price), fair_price, lower_bound, upper_bound"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.091px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
