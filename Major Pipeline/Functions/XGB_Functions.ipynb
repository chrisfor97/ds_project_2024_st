{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d6c6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor #Gradient Boosting regressor\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554fdd7f",
   "metadata": {},
   "source": [
    "# Single Model Creation for Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bb6e3",
   "metadata": {},
   "source": [
    "# Multi Model Creation for Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa63dcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_xgb_optimizer(model_data, n_estimators_list, max_depths_list, lr_list, es_rounds_list, data_frac):\n",
    "    # run_xgb_optimizer function begins\n",
    "    \n",
    "    # Process done by the function\n",
    "    # Sample the data\n",
    "    model_data = model_data.sample(frac=data_frac, random_state=42)\n",
    "    \n",
    "    # Split the data into features (X) and target (y)\n",
    "    X = model_data.drop(\"Price\", axis=1)\n",
    "    y = model_data[\"Price\"]\n",
    "\n",
    "    # First split to create training + validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Second split to create training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "\n",
    "    # Initialize lists to store models and their specifications\n",
    "    models_list = []\n",
    "    overview_data = []\n",
    "\n",
    "    # Loop over the parameters to test\n",
    "    for curr_n_estimators in n_estimators_list:\n",
    "        for curr_max_depth in max_depths_list:\n",
    "            for curr_lr in lr_list:\n",
    "                for curr_es_rounds in es_rounds_list:\n",
    "                    # Create the model\n",
    "                    curr_model = xgb.XGBRegressor(n_estimators=curr_n_estimators,\n",
    "                                                  max_depth=curr_max_depth,\n",
    "                                                  learning_rate=curr_lr,\n",
    "                                                  n_jobs=-1,\n",
    "                                                  tree_method='hist',\n",
    "                                                  eval_metric='rmse',\n",
    "                                                  random_state=42,\n",
    "                                                  early_stopping_rounds=curr_es_rounds)\n",
    "                    \n",
    "                    # Fit the model\n",
    "                    curr_model.fit(X_train, y_train, \n",
    "                                   eval_set=[(X_val, y_val)], \n",
    "                                   verbose=False)\n",
    "                    \n",
    "                    # Predict on the test data\n",
    "                    y_pred = curr_model.predict(X_test)\n",
    "                    \n",
    "                    # Calculate performance metrics\n",
    "                    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "                    r2 = r2_score(y_test, y_pred)\n",
    "                    \n",
    "                    # Save the model and its specifications\n",
    "                    models_list.append(curr_model)\n",
    "                    overview_data.append({\n",
    "                        'n_estimators': curr_n_estimators,\n",
    "                        'max_depth': curr_max_depth,\n",
    "                        'learning_rate': curr_lr,\n",
    "                        'early_stopping_rounds': curr_es_rounds,\n",
    "                        'rmse': rmse,\n",
    "                        'r2': r2\n",
    "                    })\n",
    "    \n",
    "    # Create an overview dataframe\n",
    "    overview_df = pd.DataFrame(overview_data)\n",
    "\n",
    "    return models_list, overview_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c0f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_xgb_model(model_data, n_estimators, max_depth, learning_rate, early_stopping_rounds, data_frac):\n",
    "    # create_xgb_model function begins\n",
    "    # Sample the data\n",
    "    model_data = model_data.sample(frac=data_frac, random_state=42)\n",
    "    \n",
    "    # Process done by the function\n",
    "    # Split the data into features (X) and target (y)\n",
    "    X = model_data.drop(\"Price\", axis=1)\n",
    "    y = model_data[\"Price\"]\n",
    "\n",
    "    # First split to create training + validation and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Second split to create training and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)  # 0.25 x 0.8 = 0.2\n",
    "    \n",
    "    # Create the model\n",
    "    model = xgb.XGBRegressor(n_estimators=n_estimators,\n",
    "                             max_depth=max_depth,\n",
    "                             learning_rate=learning_rate,\n",
    "                             n_jobs=-1,\n",
    "                             tree_method='hist',\n",
    "                             eval_metric='rmse',\n",
    "                             random_state=42,\n",
    "                             early_stopping_rounds=early_stopping_rounds)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train, \n",
    "              eval_set=[(X_val, y_val)], \n",
    "              verbose=False)\n",
    "    \n",
    "    # Predict on the test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return model, r2, rmse, y_test, y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
